{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "nav_menu": {
      "height": "309px",
      "width": "468px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E32UBMT7VKMm"
      },
      "source": [
        "## Prepare python environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_lm7Q-9VKMn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryOZJYQa3PG0"
      },
      "source": [
        "random_state = 5 # use this to control randomness across runs e.g., dataset partitioning"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BASGXrOy4wat"
      },
      "source": [
        "## Preparing the Glass Dataset (2 points)\n",
        "\n",
        "We will use glass dataset from UCI machine learning repository. Details for this data can be found [here](https://archive.ics.uci.edu/ml/datasets/glass+identification). The objective of the dataset is to identify the class of glass based on the following features:\n",
        "\n",
        "1.  RI: refractive index\n",
        "2.  Na: Sodium\n",
        "3.  Mg: Magnesium\n",
        "4.  Al: Aluminum\n",
        "5.  Si: Silica\n",
        "6.  K: Potassium\n",
        "7.  Ca: Calcium\n",
        "8.  Ba: Barium\n",
        "9.  Fe: Iron\n",
        "10. Type of glass (Target label)\n",
        "\n",
        "The classes of glass are:\n",
        "\n",
        "1. building_windows_float_processed \n",
        "2. building_windows_non_float_processed \n",
        "3. vehicle_windows_float_processed \n",
        "4. containers \n",
        "6. tableware \n",
        "7. headlamps\n",
        "\n",
        "Identification of glass from its content can be used for forensic analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URgO9HCN6RCl"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "tlKBDyEQDzrk",
        "outputId": "e7cd7a50-c7df-4b70-eb5a-42797566e3ca"
      },
      "source": [
        "# Download and load the dataset\n",
        "import os\n",
        "if not os.path.exists('glass.csv'): \n",
        "    !wget https://raw.githubusercontent.com/JHA-Lab/ece364_2022/master/dataset/glass.csv\n",
        "df = pd.read_csv('glass.csv')\n",
        "# Display the first five instances in the dataset\n",
        "df.head(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-21 01:25:23--  https://raw.githubusercontent.com/JHA-Lab/ece364_2022/master/dataset/glass.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9838 (9.6K) [text/plain]\n",
            "Saving to: ‘glass.csv’\n",
            "\n",
            "\rglass.csv             0%[                    ]       0  --.-KB/s               \rglass.csv           100%[===================>]   9.61K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-21 01:25:23 (46.0 MB/s) - ‘glass.csv’ saved [9838/9838]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
              "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
              "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
              "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
              "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
              "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2cdc388-d5b1-474b-b5ee-71bd9519cf50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RI</th>\n",
              "      <th>Na</th>\n",
              "      <th>Mg</th>\n",
              "      <th>Al</th>\n",
              "      <th>Si</th>\n",
              "      <th>K</th>\n",
              "      <th>Ca</th>\n",
              "      <th>Ba</th>\n",
              "      <th>Fe</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.52101</td>\n",
              "      <td>13.64</td>\n",
              "      <td>4.49</td>\n",
              "      <td>1.10</td>\n",
              "      <td>71.78</td>\n",
              "      <td>0.06</td>\n",
              "      <td>8.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.51761</td>\n",
              "      <td>13.89</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.36</td>\n",
              "      <td>72.73</td>\n",
              "      <td>0.48</td>\n",
              "      <td>7.83</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.51618</td>\n",
              "      <td>13.53</td>\n",
              "      <td>3.55</td>\n",
              "      <td>1.54</td>\n",
              "      <td>72.99</td>\n",
              "      <td>0.39</td>\n",
              "      <td>7.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.51766</td>\n",
              "      <td>13.21</td>\n",
              "      <td>3.69</td>\n",
              "      <td>1.29</td>\n",
              "      <td>72.61</td>\n",
              "      <td>0.57</td>\n",
              "      <td>8.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.51742</td>\n",
              "      <td>13.27</td>\n",
              "      <td>3.62</td>\n",
              "      <td>1.24</td>\n",
              "      <td>73.08</td>\n",
              "      <td>0.55</td>\n",
              "      <td>8.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2cdc388-d5b1-474b-b5ee-71bd9519cf50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2cdc388-d5b1-474b-b5ee-71bd9519cf50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2cdc388-d5b1-474b-b5ee-71bd9519cf50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional features to be added to the data\n",
        "df['Ca_Na'] = df.Ca*df.Na\n",
        "df['Al_Mg'] = df.Al*df.Mg\n",
        "df['Ca_Mg'] = df.Ca*df.Mg\n",
        "df['Ca_RI'] = df.Ca*df.RI"
      ],
      "metadata": {
        "id": "U1ds9iRBPJwr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRhEcln77rIK"
      },
      "source": [
        "### Extract target and descriptive features (0.5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blhp_Upk8E-Y"
      },
      "source": [
        "# Store all the features from the data in X\n",
        "X= df.drop('Type',axis=1)\n",
        "# Store all the labels in y\n",
        "y= df['Type']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdUFK3qG8Gnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ba6b912-914b-40eb-8317-b3829e2d7e2a"
      },
      "source": [
        "# Convert data to numpy array\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(214, 13)\n",
            "(214,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-JPYSnc8JQi"
      },
      "source": [
        "### Create training and validation datasets (0.5 points)\n",
        "\n",
        "\n",
        "Split the data into training and validation sets using `train_test_split`.  See [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for details. To get consistent result while splitting, set `random_state` to the value defined earlier. We use 80% of the data for training and 20% of the data for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzTzI3iT8R5x"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.2, random_state=random_state) # 80% training and 20% validation"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc40XakM8ZjC"
      },
      "source": [
        "### Preprocess the dataset (1 point)\n",
        "\n",
        "#### Preprocess the data by normalizing each feature to have zero mean and unit standard deviation. This can be done using the `StandardScaler()` function. See [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) for more details.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBcVWz4M8qi3"
      },
      "source": [
        "# Define the scaler for scaling the data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Normalize the training data\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Use the scaler defined above to standardize the validation data by applying the same transformation to the validation data.\n",
        "X_val = scaler.transform(X_val)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0ytKO6K6rW-"
      },
      "source": [
        "## Training error-based models (18 points)\n",
        "\n",
        "\n",
        "#### We will use the `sklearn` library to train a Multinomial Logistic Regression classifier and Support Vector Machines. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBAcnfZw6rW_"
      },
      "source": [
        "### Exercise 1:  Learning a Multinomial Logistic Regression classifier (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZY5Qfz36rW_"
      },
      "source": [
        "#### Use `sklearn`'s `SGDClassifier` to train a multinomial logistic regression classifier (i.e., using a one-versus-rest scheme) with Stochastic Gradient Descent. Review ch.7 and see [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) for more details. \n",
        "\n",
        "#### Set the `random_state` as defined above,  increase the `n_iter_no_change` to 100 and `max_iter` to 1000 to facilitate better convergence.  \n",
        "\n",
        "#### Report the model's accuracy over the training and validation sets.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ3SYc4J6rW_"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1hqKVGd6rW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4404614b-6c8c-4c3a-ee95-a6daf432db74"
      },
      "source": [
        "# Create Logistic Regression based classifier\n",
        "clf = SGDClassifier(loss='log', random_state=random_state, n_iter_no_change=100, max_iter=1000)\n",
        "\n",
        "# Train Classifer on training set\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "# Predict the response for train dataset\n",
        "y_pred_train = clf.predict(X_train)\n",
        "\n",
        "# Predict the response for validation dataset\n",
        "y_pred_val = clf.predict(X_val)\n",
        "\n",
        "print(\"train accuracy: %.5f\" % accuracy_score(y_train, y_pred_train))\n",
        "print(\"validation accuracy: %.5f\" % accuracy_score(y_val, y_pred_val))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train accuracy: 0.71930\n",
            "validation accuracy: 0.69767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV7PfP9G6rXA"
      },
      "source": [
        "#### Explain any performance difference observed between the training and validation datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r080wHsO6rXA"
      },
      "source": [
        "The classifier is slightly overfitting to the training dataset, resulting in lower accuracy on the validation dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IctolF7v6rXA"
      },
      "source": [
        "### Exercise 2: Learning a Support Vector Machine (SVM) (14 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uWiMMUs6rXA"
      },
      "source": [
        "#### Use `sklearn`'s `SVC` class to train an SVM (i.e., using a [one-versus-one scheme](https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-one)). Review ch.7 and see [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) for more details. \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyp0Jj3x6rXA"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5dxvcSK6rXA"
      },
      "source": [
        "#### Exercise 2a: Warm up (2 points)\n",
        "\n",
        "#### Train an SVM with a linear kernel. Set the  random_state to the value defined above. Keep all other parameters at their defaults.\n",
        "\n",
        "#### Report the model's accuracy over the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REdlLnyO6rXB",
        "outputId": "d71ae012-c6f3-4d85-d743-62484f6c7b7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf = SVC(kernel='linear', random_state=random_state)\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "print(\"training acc: %.5f\" % accuracy_score(y_train, clf.predict(X_train)))\n",
        "print(\"validation acc: %.5f\" % accuracy_score(y_val, clf.predict(X_val)))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training acc: 0.74269\n",
            "validation acc: 0.69767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJELdAX36rXB"
      },
      "source": [
        "#### Exercise 2b: Evaluate a polynomial kernel function (4 points)\n",
        "\n",
        "#### Try fitting an SVM with a polynomial kernel function and vary the degree among {1, 2, 3, 4}. Note that degree=1 yields a linear kernel. \n",
        "\n",
        "#### For each fitted classifier, report its accuracy over the training and validation sets. \n",
        "\n",
        "#### As before, set the random_state to the value defined above. Set the regularization strength `C=3`.  When the data is not linearly separable, this encourages the model to fit the training data. Keep all other parameters at their default values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6T71FR_6rXB",
        "outputId": "eaeaf670-1631-4915-9822-590dca6cdffe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for degree in [1,2,3,4]:\n",
        "    clf = SVC(kernel='poly', random_state=random_state, degree=degree, C=3)\n",
        "    clf.fit(X_train,y_train)\n",
        "    \n",
        "    print(\"Poly kernel, degree: %d\" %degree)\n",
        "    print(\"training acc: %.5f\" % accuracy_score(y_train, clf.predict(X_train)))\n",
        "    print(\"validation acc: %.5f\" % accuracy_score(y_val, clf.predict(X_val)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poly kernel, degree: 1\n",
            "training acc: 0.70760\n",
            "validation acc: 0.72093\n",
            "Poly kernel, degree: 2\n",
            "training acc: 0.73684\n",
            "validation acc: 0.74419\n",
            "Poly kernel, degree: 3\n",
            "training acc: 0.73099\n",
            "validation acc: 0.62791\n",
            "Poly kernel, degree: 4\n",
            "training acc: 0.73684\n",
            "validation acc: 0.62791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdzaOyzg6rXB"
      },
      "source": [
        "#### Explain the effect of increasing the degree of the polynomial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBeZEsy_6rXB"
      },
      "source": [
        "Increasing the degree of the polynomial kernel function allows the model to better fit the training dataset. Consequently the model overfits the training data and reduces generalization. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYfgKZuZ6rXB"
      },
      "source": [
        "#### Exercise 2c: Evaluate the radial basis kernel function (6 points)\n",
        "\n",
        "#### Try fitting an SVM with a radial basis kernel function and vary the length-scale parameter given by $\\gamma$ among {0.01, 0.1,1,10, 100}. \n",
        "\n",
        "#### For each fitted classifier, report its accuracy over the training and validation sets. \n",
        "\n",
        "#### As before, set the random_state to the value defined above. Set the regularization strength `C=10`.  When the data is not linearly separable, this encourages the model to fit the training data (read more [here](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html)). Keep all other parameters at their default values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3BCoYu66rXC",
        "outputId": "d63244c7-88ad-4acb-a3ff-b94075f78392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for gamma in [0.01,0.1,1,10,100]:\n",
        "    clf = SVC(kernel='rbf', random_state=random_state, gamma=gamma, C=10)\n",
        "    clf.fit(X_train,y_train)\n",
        "    \n",
        "    print(\"RBF kernel, gamma: \", gamma)\n",
        "    print(\"training acc: %.2f\" % accuracy_score(y_train, clf.predict(X_train)))\n",
        "    print(\"validation acc: %.2f\" % accuracy_score(y_val, clf.predict(X_val)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RBF kernel, gamma:  0.01\n",
            "training acc: 0.75\n",
            "validation acc: 0.84\n",
            "RBF kernel, gamma:  0.1\n",
            "training acc: 0.90\n",
            "validation acc: 0.72\n",
            "RBF kernel, gamma:  1\n",
            "training acc: 0.99\n",
            "validation acc: 0.60\n",
            "RBF kernel, gamma:  10\n",
            "training acc: 1.00\n",
            "validation acc: 0.53\n",
            "RBF kernel, gamma:  100\n",
            "training acc: 1.00\n",
            "validation acc: 0.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpzq9Ync6rXC"
      },
      "source": [
        "#### Comment on the effect of increasing/reducing the length-scale parameter $\\gamma$. Also, compare the performance of the classifiers trained with RBF kernel function against those trained with the polynomial and linear kernel functions (i.e., Ex. 2b). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6_JKd8S6rXC"
      },
      "source": [
        "Increasing $\\gamma$ degrades generalization. $\\gamma$ determines when points are deemed close and far. Larger $\\gamma$ reduces the radius of influence of select training examples (support vectors), so that data points are only affected by a few nearby support vectors during inference. Smaller $\\gamma$ increases the radius of influence of select training examples (support vectors), so that data points are also affected by more distant support vectors during inference. \n",
        "\n",
        "Increasing $\\gamma$ to values greater than 0.1 reduces generalization performance because the classifier effectively relies on a few training examples (support vectors) that are close to the data point in order to make its prediction. Learn more [here](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html).\n",
        "\n",
        "Classifiers trained with the RBF kernel function overfit the training data more than those trained with the polynomial and linear kernel functions. This is because the RBF kernel function maps into an infinite-dimensional feature space. The increased overfitting, esp. at large $\\gamma$, degrades generalization performance, resulting in less performant classifiers compared to classifiers trained with linear and polynomial kernel functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhxJEJpS6rXC"
      },
      "source": [
        "#### Exercise 2d: Briefly state the main difference between the logistic regression classifier and the SVM. (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jPMmTUQ6rXD"
      },
      "source": [
        "SVMs are explicitly trained to learn decision boundaries with large margins separating the classes.  "
      ]
    }
  ]
}