{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "nav_menu": {
      "height": "309px",
      "width": "468px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E32UBMT7VKMm"
      },
      "source": [
        "## Prepare python environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_lm7Q-9VKMn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryOZJYQa3PG0"
      },
      "source": [
        "random_state = 5 # Use this to control randomness across runs e.g., dataset partitioning"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BASGXrOy4wat"
      },
      "source": [
        "## Preparing the Diabetes Dataset (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the diabetes dataset from the UCI machine learning repository. Details about this dataset can be found [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database). The objective of this project is to predict whether or not a female patient has diabetes based on diagnostic measurements in the dataset.\n",
        "\n",
        "The dataset consists of several medical predictor variables (features) and one target variable indicating whether or not the person has diabetes. Predictor variables include the number of pregnancies the patient has had, glucose level, blood pressure, skin, insulin, bmi, pedigree, and age."
      ],
      "metadata": {
        "id": "7Qrhdt-A2Afs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URgO9HCN6RCl"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "6Pyo8XV46UlI",
        "outputId": "df4b707d-f3be-4d7f-8a4d-eebee59564ac"
      },
      "source": [
        "# These are the names of the columns in the dataset. They includes all features of the data and the label.\n",
        "col_names = ['pregnancies', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
        "\n",
        "# Download and load the dataset\n",
        "import os\n",
        "if not os.path.exists('diabetes.csv'): \n",
        "    !wget https://raw.githubusercontent.com/JHA-Lab/ece364_2022/master/dataset/diabetes.csv \n",
        "diabetes_data = pd.read_csv('diabetes.csv', header=1, names=col_names)\n",
        "\n",
        "FEATURE_NAMES=diabetes_data.drop('label',axis=1).columns\n",
        "\n",
        "# Display the first five instances in the dataset\n",
        "diabetes_data.head(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-11 00:48:40--  https://raw.githubusercontent.com/JHA-Lab/ece364_2022/master/dataset/diabetes.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24641 (24K) [text/plain]\n",
            "Saving to: ‘diabetes.csv’\n",
            "\n",
            "diabetes.csv        100%[===================>]  24.06K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2022-10-11 00:48:41 (6.24 MB/s) - ‘diabetes.csv’ saved [24641/24641]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   pregnancies  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
              "0            1       85  66    29        0  26.6     0.351   31      0\n",
              "1            8      183  64     0        0  23.3     0.672   32      1\n",
              "2            1       89  66    23       94  28.1     0.167   21      0\n",
              "3            0      137  40    35      168  43.1     2.288   33      1\n",
              "4            5      116  74     0        0  25.6     0.201   30      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bd7016e-ead8-41a7-89cc-52f9eaa16ff3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pregnancies</th>\n",
              "      <th>glucose</th>\n",
              "      <th>bp</th>\n",
              "      <th>skin</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree</th>\n",
              "      <th>age</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bd7016e-ead8-41a7-89cc-52f9eaa16ff3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bd7016e-ead8-41a7-89cc-52f9eaa16ff3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bd7016e-ead8-41a7-89cc-52f9eaa16ff3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXUMJrOYNfXj",
        "outputId": "d52815fb-e78f-4fa7-f2e2-35bfddc0e0ae"
      },
      "source": [
        "# Check the type of data in each column\n",
        "diabetes_data.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 767 entries, 0 to 766\n",
            "Data columns (total 9 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   pregnancies  767 non-null    int64  \n",
            " 1   glucose      767 non-null    int64  \n",
            " 2   bp           767 non-null    int64  \n",
            " 3   skin         767 non-null    int64  \n",
            " 4   insulin      767 non-null    int64  \n",
            " 5   bmi          767 non-null    float64\n",
            " 6   pedigree     767 non-null    float64\n",
            " 7   age          767 non-null    int64  \n",
            " 8   label        767 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS7PzOS76hrv"
      },
      "source": [
        "#### Look at some statistics of the data using the `describe` function in pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "sWDsbF6U6ZLT",
        "outputId": "6b760417-1155-4957-e3dd-1934cd2a223d"
      },
      "source": [
        "# Display some stats\n",
        "diabetes_data.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       pregnancies     glucose          bp        skin     insulin  \\\n",
              "count   767.000000  767.000000  767.000000  767.000000  767.000000   \n",
              "mean      3.842243  120.859192   69.101695   20.517601   79.903520   \n",
              "std       3.370877   31.978468   19.368155   15.954059  115.283105   \n",
              "min       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "25%       1.000000   99.000000   62.000000    0.000000    0.000000   \n",
              "50%       3.000000  117.000000   72.000000   23.000000   32.000000   \n",
              "75%       6.000000  140.000000   80.000000   32.000000  127.500000   \n",
              "max      17.000000  199.000000  122.000000   99.000000  846.000000   \n",
              "\n",
              "              bmi    pedigree         age       label  \n",
              "count  767.000000  767.000000  767.000000  767.000000  \n",
              "mean    31.990482    0.471674   33.219035    0.348110  \n",
              "std      7.889091    0.331497   11.752296    0.476682  \n",
              "min      0.000000    0.078000   21.000000    0.000000  \n",
              "25%     27.300000    0.243500   24.000000    0.000000  \n",
              "50%     32.000000    0.371000   29.000000    0.000000  \n",
              "75%     36.600000    0.625000   41.000000    1.000000  \n",
              "max     67.100000    2.420000   81.000000    1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c37d67d-38f0-4515-b0c3-ce1ece413745\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pregnancies</th>\n",
              "      <th>glucose</th>\n",
              "      <th>bp</th>\n",
              "      <th>skin</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree</th>\n",
              "      <th>age</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.842243</td>\n",
              "      <td>120.859192</td>\n",
              "      <td>69.101695</td>\n",
              "      <td>20.517601</td>\n",
              "      <td>79.903520</td>\n",
              "      <td>31.990482</td>\n",
              "      <td>0.471674</td>\n",
              "      <td>33.219035</td>\n",
              "      <td>0.348110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.370877</td>\n",
              "      <td>31.978468</td>\n",
              "      <td>19.368155</td>\n",
              "      <td>15.954059</td>\n",
              "      <td>115.283105</td>\n",
              "      <td>7.889091</td>\n",
              "      <td>0.331497</td>\n",
              "      <td>11.752296</td>\n",
              "      <td>0.476682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.371000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.500000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c37d67d-38f0-4515-b0c3-ce1ece413745')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c37d67d-38f0-4515-b0c3-ce1ece413745 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c37d67d-38f0-4515-b0c3-ce1ece413745');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1)\n",
        "ax.pie(diabetes_data.label.value_counts(),autopct='%1.1f%%', labels=['Not diabetes','Diabetes'], colors=['green','red'])\n",
        "plt.axis('equal')\n",
        "plt.ylabel('');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "kteOYfTwVw3d",
        "outputId": "80480303-0d8d-4a48-d986-4b0bdb688c0d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIhJ405vteOl"
      },
      "source": [
        "### Extract target and descriptive features (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIehnONbPjbZ"
      },
      "source": [
        "#### Separate the target and features from the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blhp_Upk8E-Y"
      },
      "source": [
        "# Store all the features from the data in X\n",
        "X = diabetes_data.drop('label', axis=1)\n",
        "\n",
        "# Store all the target labels in y\n",
        "y = diabetes_data['label']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdUFK3qG8Gnk"
      },
      "source": [
        "# Convert data to numpy arrays\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-JPYSnc8JQi"
      },
      "source": [
        "### Create training and validation datasets (0.5 points)\n",
        "\n",
        "Split the data into training and validation set using `train_test_split`.  See [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for details. To get consistent result while splitting, set `random_state` to the value defined earlier. We use 80% of the data for training and 20% of the data for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzTzI3iT8R5x"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.2,random_state=random_state) # 80% training and 20% validation"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess the dataset (0.5 points)\n",
        "\n",
        "#### Preprocess the dataset by normalizing each feature to have zero mean and unit standard deviation. This can be done using `StandardScaler()` function. See [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) for more details."
      ],
      "metadata": {
        "id": "_0MX4oT7fgtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the scaler for scaling the data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Normalize the training data\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Use the scaler defined above to standardize the validation data by applying the same transformation to the validation data.\n",
        "X_val = scaler.transform(X_val)"
      ],
      "metadata": {
        "id": "fDFTujIAbxlg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79Xi4_63teOo"
      },
      "source": [
        "## Training K-nearest neighbor models (18 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### We will use the `sklearn` library to train a K-nearest neighbors (kNN) classifier. Review ch.5 and see [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) for more details. "
      ],
      "metadata": {
        "id": "nZZ-sG7b2JG_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myNA80bOteOo"
      },
      "source": [
        "### Exercise 1: Learning a kNN classifier (18 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uykugy5hteOo"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaxElyimteOo"
      },
      "source": [
        "#### Exercise 1a: Evaluate the effect of the number of neighbors (6 points)\n",
        "\n",
        "#### Train kNN classifiers with different number of neighbors among {1, 5, 15, 100, length(X_train)}.\n",
        "\n",
        "#### Keep all other parameters at their default values.  \n",
        "\n",
        "#### Report the model's accuracy on the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frn2uVg2teOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb8647a-3121-48bb-dc62-2714a035aecf"
      },
      "source": [
        "for k in [1, 5, 15, 100, len(X_train)]:\n",
        "\n",
        "    clf = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "    # Train Classifer on training set\n",
        "    clf = clf.fit(X_train,y_train)\n",
        "\n",
        "    # Predict the response for training dataset\n",
        "    y_pred_train = clf.predict(X_train)\n",
        "    \n",
        "    # Predict the response for validation dataset\n",
        "    y_pred_val = clf.predict(X_val)\n",
        "\n",
        "    print(\"# neighbors: %d\"%k)\n",
        "    print(\"training accuracy: %.2f\" % accuracy_score(y_train, y_pred_train))\n",
        "    print(\"validation accuracy: %.2f\" % accuracy_score(y_val, y_pred_val))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# neighbors: 1\n",
            "training accuracy: 1.00\n",
            "validation accuracy: 0.73\n",
            "# neighbors: 5\n",
            "training accuracy: 0.83\n",
            "validation accuracy: 0.71\n",
            "# neighbors: 15\n",
            "training accuracy: 0.79\n",
            "validation accuracy: 0.71\n",
            "# neighbors: 100\n",
            "training accuracy: 0.76\n",
            "validation accuracy: 0.73\n",
            "# neighbors: 613\n",
            "training accuracy: 0.66\n",
            "validation accuracy: 0.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5pr7OuCteOp"
      },
      "source": [
        "#### Explain the effect of increasing the number of neighbors on the performance with the training and validation sets. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQLBTS2lteOp"
      },
      "source": [
        "Increasing $k$ reduces accuracy on the training dataset because the model relies on instances in addition to the point identical to the training query data point to make its classification. Increasing $k$ improves or maintains validation accuracy at low $k$ values due to better generalization but eventually reduces accuracy when $k$ becomes the entire dataset due to class imbalance. \n",
        "\n",
        "This could be due to the class imbalance and small size of the training dataset. This issue worsens with larger $k$, since more samples from the majority class contribute to the classification decision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihIPwIM6teOp"
      },
      "source": [
        "#### Exercise 1b: Evaluate the effect of a weighted kNN (6 points)\n",
        "\n",
        "#### Train kNN classifiers with distance-weighting and vary the  number of neighbors among {1, 5, 15, 100, length(X_train)}.\n",
        "\n",
        "#### Keep all other parameters at their default values.  \n",
        "\n",
        "#### Report the model's accuracy on the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdFyiE1iteOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea0ee8b-23e2-48ff-ee4c-3b03adfed1d1"
      },
      "source": [
        "for k in [1, 5, 15, 100, len(X_train)]:\n",
        "  \n",
        "    clf = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
        "    # Train Classifer on training set\n",
        "    clf = clf.fit(X_train,y_train)\n",
        "\n",
        "    # Predict the response for training dataset\n",
        "    y_pred_train = clf.predict(X_train)\n",
        "\n",
        "    #Predict the response for validation dataset\n",
        "    y_pred_val = clf.predict(X_val)\n",
        "\n",
        "    print(\"# neighbors: %d\"%k)\n",
        "    print(\"training accuracy: %.2f\" % accuracy_score(y_train, y_pred_train))\n",
        "    print(\"validation accuracy: %.2f\" % accuracy_score(y_val, y_pred_val))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# neighbors: 1\n",
            "training accuracy: 1.00\n",
            "validation accuracy: 0.73\n",
            "# neighbors: 5\n",
            "training accuracy: 1.00\n",
            "validation accuracy: 0.71\n",
            "# neighbors: 15\n",
            "training accuracy: 1.00\n",
            "validation accuracy: 0.73\n",
            "# neighbors: 100\n",
            "training accuracy: 1.00\n",
            "validation accuracy: 0.75\n",
            "# neighbors: 613\n",
            "training accuracy: 1.00\n",
            "validation accuracy: 0.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynQ08CE5teOp"
      },
      "source": [
        "#### Compare the effect of the number of neighbors on model performance (train and validation) under the distance-weighted kNN against the uniformly weighted kNN. Explain any differences observed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs4yZ-bAteOq"
      },
      "source": [
        "Increasing $k$ has no impact on training performance i.e., training accuracy remains at 100% (as achieved when $k=1$). For any point in the training set, its nearest neighbors set includes itself, for which the distance is 0, resulting in infinite weight assigned to this point. Consequently, the classification decision is effectively based only on itself*, unlike the uniformly weighted kNN for which the classification decision is equally affected by itself and the remaining neighbors. \n",
        "\n",
        "Similar to the trends observed under the uniformly weighted kNN, increasing $k$ past a certain point can reduce validation accuracy, most likely due to the small size of the training dataset (see Ex 1b. solution). \n",
        "\n",
        "However, the validation performance is generally higher under the distance-weighted kNN than under the the uniformly weighted kNN. This is because under the distance-weighted kNN, data points distant from the query, especially points from a different class, have less impact on the classification decision. In particular, distance-weighting can help counter class imbalance effects by downweighting the contributions of training data points further away from the query that most likely belong to one of the majority classes.    \n",
        "\n",
        "*In the scikit implementation, the weight for a training point with 0 distance is set to 1 and all other weights are set to 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMEqCNbVteOq"
      },
      "source": [
        "#### Exercise 1c: Evaluate the effect of the power parameter in the Minkowski distance metric (6 points)\n",
        "\n",
        "#### Train kNN classifiers with different distance functions by varying the power parameter for the Minkowski distance among {1, 2, 10, 100}.\n",
        "\n",
        "#### Fix the number of neighbors to be 15, and use the uniformly-weighted kNN. Keep all other parameters at their default values.  \n",
        "#### Report the model's accuracy over the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OwllfC3teOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "624e48c9-616a-4607-e1be-9e177d6e8e0b"
      },
      "source": [
        "for p in [1, 2, 10, 100]:\n",
        "    clf = KNeighborsClassifier(n_neighbors=15, weights='uniform', p=p)\n",
        "    # Train Classifer on training set\n",
        "    clf = clf.fit(X_train,y_train)\n",
        "\n",
        "    #Predict the response for test dataset\n",
        "    y_pred_val = clf.predict(X_val)\n",
        "\n",
        "    print(\"p: %d\"%p)\n",
        "    print(\"validation accuracy: %.2f\" % accuracy_score(y_val, y_pred_val))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p: 1\n",
            "validation accuracy: 0.75\n",
            "p: 2\n",
            "validation accuracy: 0.71\n",
            "p: 10\n",
            "validation accuracy: 0.75\n",
            "p: 100\n",
            "validation accuracy: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G4gowmIteOr"
      },
      "source": [
        "#### Explain any effect observed on the model performance upon increasing the power parameter. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv4pm9qcteOs"
      },
      "source": [
        "Increasing $p$ in this case does not change the validation set performance by much, with $p=1, 10, 100$ yielding the highest performance. \n",
        "\n",
        "Increasing $p$ amplifies larger differences between features relative to smaller differences between features. Consequently, the overall distance is affected more by features with larger differences, affecting the set of nearest neighbors. \n",
        "\n",
        "For this dataset, it seems that choosing neighbors based on differences across all features or features with larger differences both yield high performing classifiers."
      ]
    }
  ]
}